[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "minGPT",
    "section": "",
    "text": "This file will become your README and also the index of your documentation."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "minGPT",
    "section": "Install",
    "text": "Install\npip install minGPT"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "minGPT",
    "section": "How to use",
    "text": "How to use\nFill me in please! Donâ€™t forget code examples:\n\n1+1\n\n2"
  },
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "utils",
    "section": "",
    "text": "source\n\nCfgNode\n\n CfgNode (**kwargs)\n\na lightweight configuration class inspired by yacs\n\nsource\n\n\nsetup_logging\n\n setup_logging (config)\n\nmonotonous bookkeeping\n\nsource\n\n\nset_seed\n\n set_seed (seed)"
  },
  {
    "objectID": "core.html",
    "href": "core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()"
  },
  {
    "objectID": "model.html",
    "href": "model.html",
    "title": "model",
    "section": "",
    "text": "\\(\\text{GELUs} = 0.5 x\\left(1+\\tanh \\left[\\sqrt{2 / \\pi}\\left(x+0.044715 x^3\\right)\\right]\\right)\\)\n\nsource\n\nGELU\n\n GELU ()\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\nsource\n\n\nforward\n\n forward (x)\n\n\nsource\n\n\nCasualSelfAttention\n\n CasualSelfAttention (config)\n\nBase class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool\n\n# attention = CasualSelfAttention()\n\n\nsource\n\n\nGPT\n\n GPT ()\n\nGPT Language Model"
  }
]